import streamlit as st
import pandas as pd
import numpy as np
import openpyxl
from io import StringIO
import warnings
warnings.filterwarnings('ignore')

st.set_page_config(
    page_title="íšŒê³„ê°ì‚¬ JET ìë™í™” í”„ë¡œê·¸ë¨",
    page_icon="ğŸ“Š",
    layout="wide"
)

def load_data_file(uploaded_file):
    """íŒŒì¼ ì—…ë¡œë“œ ë° ë°ì´í„° ë¡œë”© í•¨ìˆ˜"""
    try:
        if uploaded_file.name.endswith('.csv'):
            # íŒŒì¼ í¬ì¸í„°ë¥¼ ì²˜ìŒìœ¼ë¡œ ë¦¬ì…‹
            uploaded_file.seek(0)
            
            # ë‹¤ì–‘í•œ ì¸ì½”ë”© ì‹œë„
            encodings = ['cp949', 'euc-kr', 'utf-8', 'utf-8-sig', 'ansi']
            df = None
            successful_encoding = None
            
            for encoding in encodings:
                try:
                    uploaded_file.seek(0)  # ê° ì‹œë„ë§ˆë‹¤ íŒŒì¼ í¬ì¸í„° ë¦¬ì…‹
                    df = pd.read_csv(uploaded_file, encoding=encoding)
                    successful_encoding = encoding
                    # ì»¬ëŸ¼ì´ ì œëŒ€ë¡œ íŒŒì‹±ë˜ì—ˆëŠ”ì§€ í™•ì¸
                    if len(df.columns) > 0 and not df.empty:
                        break
                except (UnicodeDecodeError, pd.errors.EmptyDataError, pd.errors.ParserError):
                    continue
            
            if df is None or len(df.columns) == 0:
                st.error("CSV íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                return None
                
            st.success(f"íŒŒì¼ì´ {successful_encoding} ì¸ì½”ë”©ìœ¼ë¡œ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
            
        elif uploaded_file.name.endswith(('.xlsx', '.xls')):
            df = pd.read_excel(uploaded_file)
        else:
            st.error("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. CSV ë˜ëŠ” Excel íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
            return None
        
        # ë¹ˆ DataFrame ì²´í¬
        if df.empty:
            st.error("íŒŒì¼ì´ ë¹„ì–´ìˆê±°ë‚˜ ë°ì´í„°ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ì»¬ëŸ¼ëª… ì •ë¦¬ (ì˜¤íƒ€ ìˆ˜ì • ë° ê³µë°± ì œê±°)
        df.columns = df.columns.str.strip().str.replace('ì°¨ë³€ì§„ì•¡', 'ì°¨ë³€ì”ì•¡')
        
        # ê³„ì •ì½”ë“œë¥¼ ë¬¸ìì—´ë¡œ í†µì¼
        if 'ê³„ì •ì½”ë“œ' in df.columns:
            df['ê³„ì •ì½”ë“œ'] = df['ê³„ì •ì½”ë“œ'].astype(str).str.strip()
        
        # ìˆ«ìí˜• ì»¬ëŸ¼ ë³€í™˜ ë° ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        numeric_columns = ['ì°¨ë³€ì”ì•¡', 'ëŒ€ë³€ì”ì•¡', 'ì°¨ë³€ê¸ˆì•¡', 'ëŒ€ë³€ê¸ˆì•¡']
        for col in numeric_columns:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
        
        # ë°ì´í„° ë¡œë”© ì •ë³´ í‘œì‹œ
        st.info(f"ë¡œë“œëœ ë°ì´í„°: {len(df)}í–‰, {len(df.columns)}ì—´")
        st.write("ì»¬ëŸ¼ëª…:", list(df.columns))
            
        return df
    except Exception as e:
        st.error(f"íŒŒì¼ ë¡œë”© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        return None

def validate_trial_balance(df):
    """ì‹œì‚°í‘œ ë°ì´í„° ìœ íš¨ì„± ê²€ì¦"""
    required_columns = ['ê³„ì •ì½”ë“œ', 'ê³„ì •ê³¼ëª©', 'ì°¨ë³€ì”ì•¡', 'ëŒ€ë³€ì”ì•¡']
    
    if not all(col in df.columns for col in required_columns):
        missing_cols = [col for col in required_columns if col not in df.columns]
        st.error(f"ì‹œì‚°í‘œì— í•„ìˆ˜ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_cols}")
        return False
    
    return True

def validate_journal_entries(df):
    """ë¶„ê°œì¥ ë°ì´í„° ìœ íš¨ì„± ê²€ì¦"""
    required_columns = ['ì „í‘œì¼ì', 'ì „í‘œë²ˆí˜¸', 'ê³„ì •ì½”ë“œ', 'ê³„ì •ê³¼ëª©', 'ì°¨ë³€ê¸ˆì•¡', 'ëŒ€ë³€ê¸ˆì•¡']
    
    if not all(col in df.columns for col in required_columns):
        missing_cols = [col for col in required_columns if col not in df.columns]
        st.error(f"ë¶„ê°œì¥ì— í•„ìˆ˜ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_cols}")
        return False
    
    return True

def scenario_a01_data_integrity(journal_df):
    """A01: ë°ì´í„° ìœ íš¨ì„± ê²€ì¦ ë° ë ˆì½”ë“œ ì´í•´ ì ˆì°¨"""
    issues = []
    
    # 1. ê²°ì¸¡ê°’ ê²€ì‚¬
    missing_data = journal_df.isnull().sum()
    if missing_data.any():
        issues.append(f"ê²°ì¸¡ê°’ ë°œê²¬: {missing_data[missing_data > 0].to_dict()}")
    
    # 2. ì¤‘ë³µ ë ˆì½”ë“œ ê²€ì‚¬
    duplicates = journal_df.duplicated().sum()
    if duplicates > 0:
        issues.append(f"ì¤‘ë³µ ë ˆì½”ë“œ {duplicates}ê±´ ë°œê²¬")
    
    # 3. ë°ì´í„° íƒ€ì… ê²€ì‚¬
    required_numeric = ['ì°¨ë³€ê¸ˆì•¡', 'ëŒ€ë³€ê¸ˆì•¡']
    for col in required_numeric:
        if col in journal_df.columns:
            non_numeric = journal_df[col].apply(lambda x: not isinstance(x, (int, float, np.number))).sum()
            if non_numeric > 0:
                issues.append(f"{col} ì»¬ëŸ¼ì— ìˆ«ìê°€ ì•„ë‹Œ ê°’ {non_numeric}ê±´ ë°œê²¬")
    
    # 4. ì „í‘œë²ˆí˜¸ í˜•ì‹ ê²€ì‚¬
    if 'ì „í‘œë²ˆí˜¸' in journal_df.columns:
        empty_vouchers = journal_df['ì „í‘œë²ˆí˜¸'].isnull().sum()
        if empty_vouchers > 0:
            issues.append(f"ì „í‘œë²ˆí˜¸ê°€ ëˆ„ë½ëœ í•­ëª© {empty_vouchers}ê±´ ë°œê²¬")
    
    return issues

def scenario_a02_dr_cr_test(journal_df):
    """A02: ì „í‘œë²ˆí˜¸ë³„ ì°¨ë³€ê¸ˆì•¡ê³¼ ëŒ€ë³€ê¸ˆì•¡ ì¼ì¹˜ ê²€ì¦"""
    if 'ì „í‘œë²ˆí˜¸' not in journal_df.columns:
        return ["ì „í‘œë²ˆí˜¸ ì»¬ëŸ¼ì´ ì—†ì–´ ê²€ì¦í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."]
    
    # ì „í‘œë²ˆí˜¸ë³„ ì°¨ë³€ê¸ˆì•¡ê³¼ ëŒ€ë³€ê¸ˆì•¡ í•©ê³„ ê³„ì‚°
    voucher_summary = journal_df.groupby('ì „í‘œë²ˆí˜¸').agg({
        'ì°¨ë³€ê¸ˆì•¡': 'sum',
        'ëŒ€ë³€ê¸ˆì•¡': 'sum'
    }).reset_index()
    
    # ì°¨ë³€ê³¼ ëŒ€ë³€ì´ ì¼ì¹˜í•˜ì§€ ì•ŠëŠ” ì „í‘œ ì°¾ê¸°
    unbalanced = voucher_summary[voucher_summary['ì°¨ë³€ê¸ˆì•¡'] != voucher_summary['ëŒ€ë³€ê¸ˆì•¡']]
    
    if len(unbalanced) == 0:
        return []
    else:
        unbalanced['ì°¨ì´ê¸ˆì•¡'] = unbalanced['ì°¨ë³€ê¸ˆì•¡'] - unbalanced['ëŒ€ë³€ê¸ˆì•¡']
        return unbalanced

def scenario_a03_rollforward_test(prev_tb, journal_df, curr_tb):
    """A03: ì „í‘œë°ì´í„° ê¸°ë°˜ ì‹œì‚°í‘œ ì¬êµ¬ì„±ìœ¼ë¡œ ì™„ì „ì„± ê²€ì¦"""
    if not all([prev_tb is not None, journal_df is not None, curr_tb is not None]):
        return None, "í•„ìš”í•œ ë°ì´í„°ê°€ ëª¨ë‘ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    try:
        # ë¶„ê°œì¥ì—ì„œ ê³„ì •ì½”ë“œë³„ ì§‘ê³„
        journal_summary = journal_df.groupby('ê³„ì •ì½”ë“œ').agg({
            'ì°¨ë³€ê¸ˆì•¡': 'sum',
            'ëŒ€ë³€ê¸ˆì•¡': 'sum'
        }).reset_index()
        
        # ì „ê¸° ì‹œì‚°í‘œ ì¤€ë¹„
        prev_tb_clean = prev_tb.copy()
        prev_tb_clean['ê³„ì •ì½”ë“œ'] = prev_tb_clean['ê³„ì •ì½”ë“œ'].astype(str).str.strip()
        prev_tb_clean['ì°¨ë³€ì”ì•¡'] = pd.to_numeric(prev_tb_clean['ì°¨ë³€ì”ì•¡'], errors='coerce').fillna(0)
        prev_tb_clean['ëŒ€ë³€ì”ì•¡'] = pd.to_numeric(prev_tb_clean['ëŒ€ë³€ì”ì•¡'], errors='coerce').fillna(0)
        
        # ë‹¹ê¸° ì‹œì‚°í‘œ ì¤€ë¹„
        curr_tb_clean = curr_tb.copy()
        curr_tb_clean['ê³„ì •ì½”ë“œ'] = curr_tb_clean['ê³„ì •ì½”ë“œ'].astype(str).str.strip()
        curr_tb_clean['ì°¨ë³€ì”ì•¡'] = pd.to_numeric(curr_tb_clean['ì°¨ë³€ì”ì•¡'], errors='coerce').fillna(0)
        curr_tb_clean['ëŒ€ë³€ì”ì•¡'] = pd.to_numeric(curr_tb_clean['ëŒ€ë³€ì”ì•¡'], errors='coerce').fillna(0)
        
        # ë¶„ê°œì¥ ê³„ì •ì½”ë“œ ì •ë¦¬
        journal_summary['ê³„ì •ì½”ë“œ'] = journal_summary['ê³„ì •ì½”ë“œ'].astype(str).str.strip()
        
        # ì „ê¸° ì‹œì‚°í‘œì™€ ë¶„ê°œì¥ í•©ê³„ ë³‘í•©
        merged = prev_tb_clean.merge(journal_summary, on='ê³„ì •ì½”ë“œ', how='outer', suffixes=('_prev', '_journal'))
        
        # ê²°ì¸¡ê°’ì„ 0ìœ¼ë¡œ ì²˜ë¦¬
        for col in ['ì°¨ë³€ì”ì•¡', 'ëŒ€ë³€ì”ì•¡', 'ì°¨ë³€ê¸ˆì•¡', 'ëŒ€ë³€ê¸ˆì•¡']:
            if col in merged.columns:
                merged[col] = merged[col].fillna(0)
        
        # ê³„ì‚°ëœ ë‹¹ê¸° ì”ì•¡ êµ¬í•˜ê¸°
        merged['ê³„ì‚°ëœ_ì°¨ë³€ì”ì•¡'] = merged['ì°¨ë³€ì”ì•¡'] + merged['ì°¨ë³€ê¸ˆì•¡'] - merged['ëŒ€ë³€ê¸ˆì•¡']
        merged['ê³„ì‚°ëœ_ëŒ€ë³€ì”ì•¡'] = merged['ëŒ€ë³€ì”ì•¡'] + merged['ëŒ€ë³€ê¸ˆì•¡'] - merged['ì°¨ë³€ê¸ˆì•¡']
        
        # ì°¨ë³€/ëŒ€ë³€ ì”ì•¡ ì¡°ì • (ìŒìˆ˜ì¸ ê²½ìš° ë°˜ëŒ€í¸ìœ¼ë¡œ ì´ë™)
        negative_dr_mask = merged['ê³„ì‚°ëœ_ì°¨ë³€ì”ì•¡'] < 0
        merged.loc[negative_dr_mask, 'ê³„ì‚°ëœ_ëŒ€ë³€ì”ì•¡'] = merged.loc[negative_dr_mask, 'ê³„ì‚°ëœ_ëŒ€ë³€ì”ì•¡'] + abs(merged.loc[negative_dr_mask, 'ê³„ì‚°ëœ_ì°¨ë³€ì”ì•¡'])
        merged.loc[negative_dr_mask, 'ê³„ì‚°ëœ_ì°¨ë³€ì”ì•¡'] = 0
        
        negative_cr_mask = merged['ê³„ì‚°ëœ_ëŒ€ë³€ì”ì•¡'] < 0
        merged.loc[negative_cr_mask, 'ê³„ì‚°ëœ_ì°¨ë³€ì”ì•¡'] = merged.loc[negative_cr_mask, 'ê³„ì‚°ëœ_ì°¨ë³€ì”ì•¡'] + abs(merged.loc[negative_cr_mask, 'ê³„ì‚°ëœ_ëŒ€ë³€ì”ì•¡'])
        merged.loc[negative_cr_mask, 'ê³„ì‚°ëœ_ëŒ€ë³€ì”ì•¡'] = 0
        
        # ë‹¹ê¸° ì‹œì‚°í‘œì™€ ë¹„êµ
        comparison = merged.merge(curr_tb_clean, on='ê³„ì •ì½”ë“œ', how='outer', suffixes=('_calc', '_actual'))
        
        # ê²°ì¸¡ê°’ ì²˜ë¦¬
        for col in ['ê³„ì‚°ëœ_ì°¨ë³€ì”ì•¡', 'ê³„ì‚°ëœ_ëŒ€ë³€ì”ì•¡', 'ì°¨ë³€ì”ì•¡_actual', 'ëŒ€ë³€ì”ì•¡_actual']:
            if col in comparison.columns:
                comparison[col] = comparison[col].fillna(0)
        
        # ì°¨ì´ ê³„ì‚°
        comparison['ì°¨ë³€_ì°¨ì´'] = comparison['ê³„ì‚°ëœ_ì°¨ë³€ì”ì•¡'] - comparison['ì°¨ë³€ì”ì•¡_actual']
        comparison['ëŒ€ë³€_ì°¨ì´'] = comparison['ê³„ì‚°ëœ_ëŒ€ë³€ì”ì•¡'] - comparison['ëŒ€ë³€ì”ì•¡_actual']
        
        # ì°¨ì´ê°€ ìˆëŠ” í•­ëª©ë§Œ í•„í„°ë§ (0.01ì› ì´ìƒ ì°¨ì´)
        differences = comparison[(abs(comparison['ì°¨ë³€_ì°¨ì´']) > 0.01) | (abs(comparison['ëŒ€ë³€_ì°¨ì´']) > 0.01)]
        
        return differences, None
        
    except Exception as e:
        return None, f"Roll-forward í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

def scenario_b01_large_items_test(journal_df, materiality_threshold=1000000):
    """B01: ì†ìµê³„ì •ë³„ ì¤‘ìš”ì„±ê¸ˆì•¡ ê¸°ì¤€ ë¶„ì„"""
    # ì†ìµê³„ì • ì½”ë“œ íŒ¨í„´ (ì¼ë°˜ì ìœ¼ë¡œ 4ë¡œ ì‹œì‘í•˜ëŠ” ìˆ˜ìµ, 5ë¡œ ì‹œì‘í•˜ëŠ” ë¹„ìš©)
    pl_accounts = journal_df[journal_df['ê³„ì •ì½”ë“œ'].astype(str).str.startswith(('4', '5'))]
    
    if len(pl_accounts) == 0:
        return pd.DataFrame(), "ì†ìµê³„ì •ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    # ê³„ì •ë³„ ê¸ˆì•¡ ì§‘ê³„
    pl_summary = pl_accounts.groupby(['ê³„ì •ì½”ë“œ', 'ê³„ì •ê³¼ëª©']).agg({
        'ì°¨ë³€ê¸ˆì•¡': 'sum',
        'ëŒ€ë³€ê¸ˆì•¡': 'sum'
    }).reset_index()
    
    pl_summary['ìˆœê¸ˆì•¡'] = pl_summary['ì°¨ë³€ê¸ˆì•¡'] - pl_summary['ëŒ€ë³€ê¸ˆì•¡']
    
    # ì¤‘ìš”ì„±ê¸ˆì•¡ ê¸°ì¤€ ì´ˆê³¼ í•­ëª©
    large_items = pl_summary[abs(pl_summary['ìˆœê¸ˆì•¡']) >= materiality_threshold]
    
    return large_items, None

def scenario_b02_unmatched_accounts(journal_df, chart_of_accounts=None):
    """B02: CoA ê¸°ì¤€ ë¹„ì •ìƒì ì¸ ê³„ì • ì‚¬ìš© ì „í‘œ í™•ì¸"""
    if chart_of_accounts is None:
        # ê¸°ë³¸ì ì¸ ê³„ì •ì½”ë“œ íŒ¨í„´ ê²€ì‚¬
        account_codes = journal_df['ê³„ì •ì½”ë“œ'].astype(str)
        
        # ì¼ë°˜ì ì´ì§€ ì•Šì€ íŒ¨í„´ (ì˜ˆ: ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸´ ê³„ì •ì½”ë“œ, íŠ¹ìˆ˜ë¬¸ì í¬í•¨)
        unusual_patterns = account_codes[
            (account_codes.str.len() < 3) | 
            (account_codes.str.len() > 10) |
            (~account_codes.str.match(r'^[0-9A-Za-z]+$', na=False))
        ]
        
        if len(unusual_patterns) > 0:
            unmatched_entries = journal_df[journal_df['ê³„ì •ì½”ë“œ'].astype(str).isin(unusual_patterns)]
            return unmatched_entries
    
    return pd.DataFrame()

def scenario_b03_new_accounts(journal_df, prev_tb_df):
    """B03: ì‹ ê·œ ìƒì„± ê³„ì •ê³¼ëª© ì‚¬ìš© ì „í‘œ ì¶”ì¶œ"""
    if prev_tb_df is None:
        return pd.DataFrame(), "ì „ê¸° ì‹œì‚°í‘œê°€ ì—†ì–´ ì‹ ê·œ ê³„ì •ì„ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # ì „ê¸° ì‹œì‚°í‘œì˜ ê³„ì •ì½”ë“œ ëª©ë¡
    prev_accounts = set(prev_tb_df['ê³„ì •ì½”ë“œ'].astype(str))
    
    # ë¶„ê°œì¥ì˜ ê³„ì •ì½”ë“œ ëª©ë¡
    current_accounts = set(journal_df['ê³„ì •ì½”ë“œ'].astype(str))
    
    # ì‹ ê·œ ìƒì„± ê³„ì •ì½”ë“œ
    new_accounts = current_accounts - prev_accounts
    
    if len(new_accounts) == 0:
        return pd.DataFrame(), None
    
    # ì‹ ê·œ ê³„ì •ì„ ì‚¬ìš©í•œ ì „í‘œ ì¶”ì¶œ
    new_account_entries = journal_df[journal_df['ê³„ì •ì½”ë“œ'].astype(str).isin(new_accounts)]
    
    return new_account_entries, None

def scenario_b04_seldom_used_accounts(journal_df, frequency_threshold=5):
    """B04: ì €ë¹ˆë„ ì‚¬ìš© ê³„ì • í¬í•¨ ì „í‘œ ì ì •ì„± í™•ì¸"""
    # ê³„ì •ë³„ ì‚¬ìš© ë¹ˆë„ ê³„ì‚°
    account_frequency = journal_df['ê³„ì •ì½”ë“œ'].value_counts()
    
    # ì €ë¹ˆë„ ì‚¬ìš© ê³„ì • (threshold ì´í•˜)
    seldom_used = account_frequency[account_frequency <= frequency_threshold].index
    
    if len(seldom_used) == 0:
        return pd.DataFrame(), None
    
    # ì €ë¹ˆë„ ê³„ì •ì„ ì‚¬ìš©í•œ ì „í‘œ ì¶”ì¶œ
    seldom_entries = journal_df[journal_df['ê³„ì •ì½”ë“œ'].isin(seldom_used)]
    
    return seldom_entries, None

def scenario_b05_unusual_user(journal_df, authorized_users=None):
    """B05: ì¸ì‚¬ì •ë³´ ì™¸ ì‚¬ìš©ì ì‘ì„± ì „í‘œ í™•ì¸"""
    if 'ì…ë ¥ì‚¬ì›' not in journal_df.columns:
        return pd.DataFrame(), "ì…ë ¥ì‚¬ì› ì»¬ëŸ¼ì´ ì—†ì–´ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # ê¸°ë³¸ ìŠ¹ì¸ëœ ì‚¬ìš©ì ëª©ë¡ (ì‹¤ì œë¡œëŠ” ì¸ì‚¬ ì‹œìŠ¤í…œì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨)
    if authorized_users is None:
        # ì‚¬ìš©ì íŒ¨í„´ ë¶„ì„ìœ¼ë¡œ ì¼ë°˜ì ì´ì§€ ì•Šì€ ì‚¬ìš©ì ì°¾ê¸°
        user_counts = journal_df['ì…ë ¥ì‚¬ì›'].value_counts()
        
        # ë§¤ìš° ì ê²Œ ì‚¬ìš©í•œ ì‚¬ìš©ìë“¤ (1-2íšŒë§Œ ì‚¬ìš©)
        unusual_users = user_counts[user_counts <= 2].index
        
        # ì‹œìŠ¤í…œ ê³„ì •ìœ¼ë¡œ ë³´ì´ëŠ” ì‚¬ìš©ì (ì˜ˆ: SYSTEM, ADMIN ë“±)
        system_pattern_users = journal_df[
            journal_df['ì…ë ¥ì‚¬ì›'].astype(str).str.contains('SYSTEM|ADMIN|TEST|AUTO', case=False, na=False)
        ]['ì…ë ¥ì‚¬ì›'].unique()
        
        all_unusual = list(unusual_users) + list(system_pattern_users)
    else:
        # ìŠ¹ì¸ëœ ì‚¬ìš©ì ëª©ë¡ì— ì—†ëŠ” ì‚¬ìš©ì
        all_users = journal_df['ì…ë ¥ì‚¬ì›'].unique()
        all_unusual = [user for user in all_users if user not in authorized_users]
    
    if len(all_unusual) == 0:
        return pd.DataFrame(), None
    
    unusual_entries = journal_df[journal_df['ì…ë ¥ì‚¬ì›'].isin(all_unusual)]
    
    return unusual_entries, None

def scenario_b06_inappropriate_user(journal_df, user_roles=None):
    """B06: ì „í‘œì…ë ¥ê¶Œí•œ ì—†ëŠ” ì‚¬ìš©ì ì „í‘œ í™•ì¸"""
    if 'ì…ë ¥ì‚¬ì›' not in journal_df.columns:
        return pd.DataFrame(), "ì…ë ¥ì‚¬ì› ì»¬ëŸ¼ì´ ì—†ì–´ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # ì‹¤ì œë¡œëŠ” ê¶Œí•œ ì‹œìŠ¤í…œì—ì„œ ê°€ì ¸ì™€ì•¼ í•˜ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” íŒ¨í„´ìœ¼ë¡œ ë¶„ì„
    if user_roles is None:
        # ì¼ë°˜ì ìœ¼ë¡œ ì…ë ¥ê¶Œí•œì´ ì—†ì„ ê²ƒìœ¼ë¡œ ë³´ì´ëŠ” ì‚¬ìš©ì íŒ¨í„´
        # ì˜ˆ: ì„ì›, ê°ì‚¬, ì™¸ë¶€ ë“±
        inappropriate_patterns = ['CEO', 'CFO', 'ê°ì‚¬', 'ì™¸ë¶€', 'GUEST', 'ì„ì›']
        
        inappropriate_users = []
        for pattern in inappropriate_patterns:
            pattern_users = journal_df[
                journal_df['ì…ë ¥ì‚¬ì›'].astype(str).str.contains(pattern, case=False, na=False)
            ]['ì…ë ¥ì‚¬ì›'].unique()
            inappropriate_users.extend(pattern_users)
    else:
        # ê¶Œí•œì´ ì—†ëŠ” ì‚¬ìš©ì ëª©ë¡ì—ì„œ ì‹¤ì œë¡œ ì…ë ¥í•œ ì‚¬ìš©ì ì°¾ê¸°
        inappropriate_users = [user for user in journal_df['ì…ë ¥ì‚¬ì›'].unique() 
                             if user in user_roles and user_roles[user] != 'input_authorized']
    
    if len(inappropriate_users) == 0:
        return pd.DataFrame(), None
    
    inappropriate_entries = journal_df[journal_df['ì…ë ¥ì‚¬ì›'].isin(inappropriate_users)]
    
    return inappropriate_entries, None

def scenario_b07_back_dated_entries(journal_df, fiscal_year_end='2023-12-31'):
    """B07: ê¸°í‘œì¼/ì…ë ¥ì¼ ë¹„êµë¡œ ê²°ì‚°ì¼ ì´í›„ ì…ë ¥ ì „í‘œ ì¶”ì¶œ"""
    # ì…ë ¥ì¼ ì»¬ëŸ¼ì´ ìˆë‹¤ê³  ê°€ì •í•˜ê³ , ì—†ìœ¼ë©´ ìŠ¤í‚µ
    if 'ì…ë ¥ì¼ì' not in journal_df.columns:
        return pd.DataFrame(), "ì…ë ¥ì¼ì ì»¬ëŸ¼ì´ ì—†ì–´ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    try:
        fiscal_end = pd.to_datetime(fiscal_year_end)
        journal_copy = journal_df.copy()
        journal_copy['ì „í‘œì¼ì'] = pd.to_datetime(journal_copy['ì „í‘œì¼ì'])
        journal_copy['ì…ë ¥ì¼ì'] = pd.to_datetime(journal_copy['ì…ë ¥ì¼ì'])
        
        # ê²°ì‚°ì¼ ì´ì „ ì „í‘œì´ì§€ë§Œ ê²°ì‚°ì¼ ì´í›„ì— ì…ë ¥ëœ ì „í‘œ
        back_dated = journal_copy[
            (journal_copy['ì „í‘œì¼ì'] <= fiscal_end) & 
            (journal_copy['ì…ë ¥ì¼ì'] > fiscal_end)
        ]
        
        return back_dated, None
    except Exception as e:
        return pd.DataFrame(), f"ë‚ ì§œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

def scenario_b08_create_approve_same(journal_df):
    """B08: ì…ë ¥ìì™€ ìŠ¹ì¸ì ë™ì¼ ì „í‘œ ì¶”ì¶œ"""
    if 'ì…ë ¥ì‚¬ì›' not in journal_df.columns or 'ìŠ¹ì¸ì' not in journal_df.columns:
        return pd.DataFrame(), "ì…ë ¥ì‚¬ì› ë˜ëŠ” ìŠ¹ì¸ì ì»¬ëŸ¼ì´ ì—†ì–´ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    # ì…ë ¥ìì™€ ìŠ¹ì¸ìê°€ ë™ì¼í•œ ì „í‘œ
    same_user_entries = journal_df[journal_df['ì…ë ¥ì‚¬ì›'] == journal_df['ìŠ¹ì¸ì']]
    
    return same_user_entries, None

def scenario_b09_corresponding_accounts(journal_df):
    """B09: ë¹„ì •ìƒì ì¸ ê³„ì • ì¡°í•© ì „í‘œ ì¶”ì¶œ"""
    # ì „í‘œë²ˆí˜¸ë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ê³„ì • ì¡°í•© ë¶„ì„
    voucher_groups = journal_df.groupby('ì „í‘œë²ˆí˜¸')
    
    unusual_combinations = []
    
    for voucher_no, group in voucher_groups:
        accounts = group['ê³„ì •ì½”ë“œ'].astype(str).tolist()
        account_names = group['ê³„ì •ê³¼ëª©'].tolist()
        
        # ë¹„ì •ìƒì ì¸ ì¡°í•© íŒ¨í„´ ê²€ì‚¬
        # 1. í˜„ê¸ˆê³¼ í˜„ê¸ˆ ê°„ì˜ ê±°ë˜ (ì˜ˆ: í˜„ê¸ˆ -> í˜„ê¸ˆ)
        cash_accounts = ['101', '102', '103']  # ì¼ë°˜ì ì¸ í˜„ê¸ˆì„± ìì‚° ê³„ì •
        cash_in_voucher = [acc for acc in accounts if acc.startswith(tuple(cash_accounts))]
        
        if len(cash_in_voucher) >= 2:
            unusual_combinations.append({
                'ì „í‘œë²ˆí˜¸': voucher_no,
                'ë¬¸ì œìœ í˜•': 'í˜„ê¸ˆ-í˜„ê¸ˆ ê±°ë˜',
                'ê´€ë ¨ê³„ì •': ', '.join(cash_in_voucher),
                'ê±°ë˜ë‚´ì—­': group
            })
        
        # 2. ìì‚°ê³¼ ë¶€ì±„ì˜ ì§ì ‘ì ì¸ ìƒê³„
        assets = [acc for acc in accounts if acc.startswith(('1', '2'))]  # ìì‚°: 1, íˆ¬ììì‚°: 2
        liabilities = [acc for acc in accounts if acc.startswith('3')]  # ë¶€ì±„: 3
        
        if len(assets) > 0 and len(liabilities) > 0 and len(group) == 2:
            # ë‹¨ìˆœí•œ ìì‚°-ë¶€ì±„ ì§ì ‘ ìƒê³„ (ìˆ˜ìµ/ë¹„ìš© ì—†ì´)
            revenue_expense = [acc for acc in accounts if acc.startswith(('4', '5'))]
            if len(revenue_expense) == 0:
                unusual_combinations.append({
                    'ì „í‘œë²ˆí˜¸': voucher_no,
                    'ë¬¸ì œìœ í˜•': 'ìì‚°-ë¶€ì±„ ì§ì ‘ìƒê³„',
                    'ê´€ë ¨ê³„ì •': ', '.join(accounts),
                    'ê±°ë˜ë‚´ì—­': group
                })
    
    if len(unusual_combinations) == 0:
        return pd.DataFrame(), None
    
    # ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
    result_df = pd.DataFrame()
    for combo in unusual_combinations:
        combo_df = combo['ê±°ë˜ë‚´ì—­'].copy()
        combo_df['ë¬¸ì œìœ í˜•'] = combo['ë¬¸ì œìœ í˜•']
        result_df = pd.concat([result_df, combo_df], ignore_index=True)
    
    return result_df, None

# Streamlit UI
st.title("ğŸ“Š íšŒê³„ê°ì‚¬ JET(Journal Entry Testing) ìë™í™” í”„ë¡œê·¸ë¨")
st.markdown("---")

# ì‚¬ì´ë“œë°”
st.sidebar.header("ğŸ“ íŒŒì¼ ì—…ë¡œë“œ")

# íŒŒì¼ ì—…ë¡œë“œ
prev_tb_file = st.sidebar.file_uploader("ì „ê¸° ì‹œì‚°í‘œ", type=['csv', 'xlsx'], key="prev_tb")
journal_file = st.sidebar.file_uploader("ë¶„ê°œì¥", type=['csv', 'xlsx'], key="journal")
curr_tb_file = st.sidebar.file_uploader("ë‹¹ê¸° ì‹œì‚°í‘œ", type=['csv', 'xlsx'], key="curr_tb")

st.sidebar.markdown("---")
st.sidebar.header("ğŸ” JET ì‹œë‚˜ë¦¬ì˜¤ ì„ íƒ")

# í•„ìˆ˜ ì‹œë‚˜ë¦¬ì˜¤
st.sidebar.subheader("í•„ìˆ˜ ì‹œë‚˜ë¦¬ì˜¤ (Essential)")
scenario_a01 = st.sidebar.checkbox("A01: ë°ì´í„° ìœ íš¨ì„± ê²€ì¦", value=True)
scenario_a02 = st.sidebar.checkbox("A02: ì „í‘œ ì°¨ëŒ€í‰í˜• ê²€ì¦", value=True)
scenario_a03 = st.sidebar.checkbox("A03: ì‹œì‚°í‘œ Roll-forward ê²€ì¦", value=True)

# ì„ íƒ ì‹œë‚˜ë¦¬ì˜¤
st.sidebar.subheader("ì„ íƒ ì‹œë‚˜ë¦¬ì˜¤ (Optional)")
scenario_b01 = st.sidebar.checkbox("B01: ì†ìµê³„ì • ì¤‘ìš”ì„±ê¸ˆì•¡ ë¶„ì„")
scenario_b02 = st.sidebar.checkbox("B02: ë¹„ì •ìƒ ê³„ì • ì‚¬ìš© ê²€ì‚¬")
scenario_b03 = st.sidebar.checkbox("B03: ì‹ ê·œ ìƒì„± ê³„ì •ê³¼ëª© ê²€ì‚¬")
scenario_b04 = st.sidebar.checkbox("B04: ì €ë¹ˆë„ ì‚¬ìš© ê³„ì • ê²€ì‚¬")
scenario_b05 = st.sidebar.checkbox("B05: ë¹„ì •ìƒ ì‚¬ìš©ì ê²€ì‚¬")
scenario_b06 = st.sidebar.checkbox("B06: ê¶Œí•œ ì—†ëŠ” ì‚¬ìš©ì ê²€ì‚¬")
scenario_b07 = st.sidebar.checkbox("B07: ê¸°í‘œì¼ ì´í›„ ì…ë ¥ ì „í‘œ ë¶„ì„")
scenario_b08 = st.sidebar.checkbox("B08: ì…ë ¥ì-ìŠ¹ì¸ì ë™ì¼ ê²€ì‚¬")
scenario_b09 = st.sidebar.checkbox("B09: ë¹„ì •ìƒ ê³„ì • ì¡°í•© ê²€ì‚¬")

# íŒŒë¼ë¯¸í„° ì„¤ì •
st.sidebar.subheader("ë¶„ì„ íŒŒë¼ë¯¸í„°")
if scenario_b01:
    materiality = st.sidebar.number_input("ì¤‘ìš”ì„±ê¸ˆì•¡ ê¸°ì¤€", value=1000000, step=100000)

if scenario_b04:
    frequency_threshold = st.sidebar.number_input("ì €ë¹ˆë„ ê¸°ì¤€ (ì‚¬ìš©íšŸìˆ˜)", value=5, step=1, min_value=1)

if scenario_b07:
    fiscal_year_end = st.sidebar.date_input("íšŒê³„ì—°ë„ ì¢…ë£Œì¼", value=pd.to_datetime('2023-12-31'))
    fiscal_year_end = fiscal_year_end.strftime('%Y-%m-%d')

# ë©”ì¸ ì˜ì—­
col1, col2 = st.columns([2, 1])

with col1:
    st.header("ğŸ“ˆ ë¶„ì„ ê²°ê³¼")
    
    # ë°ì´í„° ë¡œë”©
    prev_tb_df = load_data_file(prev_tb_file) if prev_tb_file else None
    journal_df = load_data_file(journal_file) if journal_file else None
    curr_tb_df = load_data_file(curr_tb_file) if curr_tb_file else None
    
    if journal_df is not None and validate_journal_entries(journal_df):
        
        # A01: ë°ì´í„° ìœ íš¨ì„± ê²€ì¦
        if scenario_a01:
            with st.expander("ğŸ” A01: ë°ì´í„° ìœ íš¨ì„± ê²€ì¦ ê²°ê³¼", expanded=True):
                with st.spinner("ë°ì´í„° ìœ íš¨ì„±ì„ ê²€ì¦í•˜ëŠ” ì¤‘..."):
                    integrity_issues = scenario_a01_data_integrity(journal_df)
                    
                    if not integrity_issues:
                        st.success("âœ… ë°ì´í„° ìœ íš¨ì„± ê²€ì¦ í†µê³¼: ë°œê²¬ëœ ë¬¸ì œê°€ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        st.warning("âš ï¸ ë°ì´í„° ìœ íš¨ì„± ë¬¸ì œ ë°œê²¬:")
                        for issue in integrity_issues:
                            st.write(f"- {issue}")
        
        # A02: ì „í‘œ ì°¨ëŒ€í‰í˜• ê²€ì¦
        if scenario_a02:
            with st.expander("âš–ï¸ A02: ì „í‘œ ì°¨ëŒ€í‰í˜• ê²€ì¦ ê²°ê³¼", expanded=True):
                with st.spinner("ì „í‘œë³„ ì°¨ëŒ€í‰í˜•ì„ ê²€ì¦í•˜ëŠ” ì¤‘..."):
                    unbalanced_vouchers = scenario_a02_dr_cr_test(journal_df)
                    
                    if isinstance(unbalanced_vouchers, list) and not unbalanced_vouchers:
                        st.success("âœ… ì „í‘œ ì°¨ëŒ€í‰í˜• ê²€ì¦ í†µê³¼: ëª¨ë“  ì „í‘œì˜ ì°¨ë³€ê³¼ ëŒ€ë³€ì´ ì¼ì¹˜í•©ë‹ˆë‹¤.")
                    elif isinstance(unbalanced_vouchers, pd.DataFrame) and len(unbalanced_vouchers) > 0:
                        st.error(f"âŒ ì°¨ëŒ€í‰í˜• ì˜¤ë¥˜ ë°œê²¬: {len(unbalanced_vouchers)}ê±´ì˜ ë¶ˆì¼ì¹˜ ì „í‘œ")
                        st.dataframe(unbalanced_vouchers)
                    else:
                        st.info("â„¹ï¸ ì „í‘œë²ˆí˜¸ ì •ë³´ê°€ ë¶€ì¡±í•˜ì—¬ ê²€ì¦í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # A03: Roll-forward í…ŒìŠ¤íŠ¸
        if scenario_a03:
            with st.expander("ğŸ”„ A03: ì‹œì‚°í‘œ Roll-forward ê²€ì¦ ê²°ê³¼", expanded=True):
                if prev_tb_df is not None and curr_tb_df is not None:
                    if validate_trial_balance(prev_tb_df) and validate_trial_balance(curr_tb_df):
                        with st.spinner("ì‹œì‚°í‘œ Roll-forwardë¥¼ ê²€ì¦í•˜ëŠ” ì¤‘..."):
                            differences, error_msg = scenario_a03_rollforward_test(prev_tb_df, journal_df, curr_tb_df)
                            
                            if error_msg:
                                st.error(f"âŒ {error_msg}")
                            elif differences is not None and len(differences) == 0:
                                st.success("âœ… Roll-forward ê²€ì¦ í†µê³¼: ê³„ì‚°ëœ ì‹œì‚°í‘œì™€ ì‹¤ì œ ì‹œì‚°í‘œê°€ ì¼ì¹˜í•©ë‹ˆë‹¤.")
                            elif differences is not None and len(differences) > 0:
                                st.warning(f"âš ï¸ Roll-forward ì°¨ì´ ë°œê²¬: {len(differences)}ê±´ì˜ ë¶ˆì¼ì¹˜ í•­ëª©")
                                
                                # ì£¼ìš” ì°¨ì´ í•­ëª©ë§Œ í‘œì‹œ
                                display_columns = ['ê³„ì •ì½”ë“œ', 'ê³„ì •ê³¼ëª©_prev', 'ê³„ì‚°ëœ_ì°¨ë³€ì”ì•¡', 'ì°¨ë³€ì”ì•¡_actual', 
                                                 'ê³„ì‚°ëœ_ëŒ€ë³€ì”ì•¡', 'ëŒ€ë³€ì”ì•¡_actual', 'ì°¨ë³€_ì°¨ì´', 'ëŒ€ë³€_ì°¨ì´']
                                available_columns = [col for col in display_columns if col in differences.columns]
                                
                                if available_columns:
                                    st.dataframe(differences[available_columns])
                                else:
                                    st.dataframe(differences)
                    else:
                        st.error("âŒ ì‹œì‚°í‘œ ë°ì´í„° í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                else:
                    st.info("â„¹ï¸ ì‹œì‚°í‘œ íŒŒì¼(ì „ê¸°, ë‹¹ê¸°)ì„ ëª¨ë‘ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
        
        # B01: ì†ìµê³„ì • ì¤‘ìš”ì„±ê¸ˆì•¡ ë¶„ì„
        if scenario_b01:
            with st.expander("ğŸ’° B01: ì†ìµê³„ì • ì¤‘ìš”ì„±ê¸ˆì•¡ ë¶„ì„ ê²°ê³¼", expanded=False):
                with st.spinner("ì†ìµê³„ì •ì„ ë¶„ì„í•˜ëŠ” ì¤‘..."):
                    large_items, error_msg = scenario_b01_large_items_test(journal_df, materiality)
                    
                    if error_msg:
                        st.warning(f"âš ï¸ {error_msg}")
                    elif len(large_items) == 0:
                        st.success(f"âœ… ì¤‘ìš”ì„±ê¸ˆì•¡({materiality:,}ì›) ê¸°ì¤€ ì´ˆê³¼ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        st.warning(f"âš ï¸ ì¤‘ìš”ì„±ê¸ˆì•¡ ê¸°ì¤€ ì´ˆê³¼ í•­ëª© {len(large_items)}ê±´ ë°œê²¬")
                        st.dataframe(large_items)
        
        # B02: ë¹„ì •ìƒ ê³„ì • ì‚¬ìš© ê²€ì‚¬
        if scenario_b02:
            with st.expander("ğŸš¨ B02: ë¹„ì •ìƒ ê³„ì • ì‚¬ìš© ê²€ì‚¬ ê²°ê³¼", expanded=False):
                with st.spinner("ë¹„ì •ìƒ ê³„ì • ì‚¬ìš©ì„ ê²€ì‚¬í•˜ëŠ” ì¤‘..."):
                    unmatched_accounts = scenario_b02_unmatched_accounts(journal_df)
                    
                    if len(unmatched_accounts) == 0:
                        st.success("âœ… ë¹„ì •ìƒì ì¸ ê³„ì • ì‚¬ìš©ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    else:
                        st.warning(f"âš ï¸ ë¹„ì •ìƒì ì¸ ê³„ì • ì‚¬ìš© {len(unmatched_accounts)}ê±´ ë°œê²¬")
                        st.dataframe(unmatched_accounts)
        
        # B03: ì‹ ê·œ ìƒì„± ê³„ì •ê³¼ëª© ê²€ì‚¬
        if scenario_b03:
            with st.expander("ğŸ†• B03: ì‹ ê·œ ìƒì„± ê³„ì •ê³¼ëª© ê²€ì‚¬ ê²°ê³¼", expanded=False):
                with st.spinner("ì‹ ê·œ ê³„ì •ê³¼ëª©ì„ ë¶„ì„í•˜ëŠ” ì¤‘..."):
                    new_account_entries, error_msg = scenario_b03_new_accounts(journal_df, prev_tb_df)
                    
                    if error_msg:
                        st.warning(f"âš ï¸ {error_msg}")
                    elif len(new_account_entries) == 0:
                        st.success("âœ… ì‹ ê·œ ìƒì„± ê³„ì •ê³¼ëª©ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    else:
                        st.warning(f"âš ï¸ ì‹ ê·œ ê³„ì •ê³¼ëª© ì‚¬ìš© ì „í‘œ {len(new_account_entries)}ê±´ ë°œê²¬")
                        st.dataframe(new_account_entries)
        
        # B04: ì €ë¹ˆë„ ì‚¬ìš© ê³„ì • ê²€ì‚¬
        if scenario_b04:
            with st.expander("ğŸ” B04: ì €ë¹ˆë„ ì‚¬ìš© ê³„ì • ê²€ì‚¬ ê²°ê³¼", expanded=False):
                with st.spinner("ì €ë¹ˆë„ ì‚¬ìš© ê³„ì •ì„ ë¶„ì„í•˜ëŠ” ì¤‘..."):
                    seldom_entries, error_msg = scenario_b04_seldom_used_accounts(journal_df, frequency_threshold)
                    
                    if error_msg:
                        st.warning(f"âš ï¸ {error_msg}")
                    elif len(seldom_entries) == 0:
                        st.success(f"âœ… ì €ë¹ˆë„({frequency_threshold}íšŒ ì´í•˜) ì‚¬ìš© ê³„ì •ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    else:
                        st.warning(f"âš ï¸ ì €ë¹ˆë„ ì‚¬ìš© ê³„ì • ì „í‘œ {len(seldom_entries)}ê±´ ë°œê²¬")
                        st.dataframe(seldom_entries)
        
        # B05: ë¹„ì •ìƒ ì‚¬ìš©ì ê²€ì‚¬
        if scenario_b05:
            with st.expander("ğŸ‘¤ B05: ë¹„ì •ìƒ ì‚¬ìš©ì ê²€ì‚¬ ê²°ê³¼", expanded=False):
                with st.spinner("ë¹„ì •ìƒ ì‚¬ìš©ìë¥¼ ë¶„ì„í•˜ëŠ” ì¤‘..."):
                    unusual_entries, error_msg = scenario_b05_unusual_user(journal_df)
                    
                    if error_msg:
                        st.warning(f"âš ï¸ {error_msg}")
                    elif len(unusual_entries) == 0:
                        st.success("âœ… ë¹„ì •ìƒì ì¸ ì‚¬ìš©ìê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    else:
                        st.warning(f"âš ï¸ ë¹„ì •ìƒ ì‚¬ìš©ì ì „í‘œ {len(unusual_entries)}ê±´ ë°œê²¬")
                        st.dataframe(unusual_entries)
        
        # B06: ê¶Œí•œ ì—†ëŠ” ì‚¬ìš©ì ê²€ì‚¬
        if scenario_b06:
            with st.expander("ğŸš« B06: ê¶Œí•œ ì—†ëŠ” ì‚¬ìš©ì ê²€ì‚¬ ê²°ê³¼", expanded=False):
                with st.spinner("ê¶Œí•œ ì—†ëŠ” ì‚¬ìš©ìë¥¼ ë¶„ì„í•˜ëŠ” ì¤‘..."):
                    inappropriate_entries, error_msg = scenario_b06_inappropriate_user(journal_df)
                    
                    if error_msg:
                        st.warning(f"âš ï¸ {error_msg}")
                    elif len(inappropriate_entries) == 0:
                        st.success("âœ… ê¶Œí•œ ì—†ëŠ” ì‚¬ìš©ìê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    else:
                        st.warning(f"âš ï¸ ê¶Œí•œ ì—†ëŠ” ì‚¬ìš©ì ì „í‘œ {len(inappropriate_entries)}ê±´ ë°œê²¬")
                        st.dataframe(inappropriate_entries)
        
        # B07: ê¸°í‘œì¼ ì´í›„ ì…ë ¥ ì „í‘œ ë¶„ì„
        if scenario_b07:
            with st.expander("ğŸ“… B07: ê¸°í‘œì¼ ì´í›„ ì…ë ¥ ì „í‘œ ë¶„ì„ ê²°ê³¼", expanded=False):
                with st.spinner("ê¸°í‘œì¼ ì´í›„ ì…ë ¥ ì „í‘œë¥¼ ë¶„ì„í•˜ëŠ” ì¤‘..."):
                    back_dated, error_msg = scenario_b07_back_dated_entries(journal_df, fiscal_year_end)
                    
                    if error_msg:
                        st.warning(f"âš ï¸ {error_msg}")
                    elif len(back_dated) == 0:
                        st.success("âœ… ê²°ì‚°ì¼ ì´í›„ ì…ë ¥ëœ ì „í‘œê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    else:
                        st.warning(f"âš ï¸ ê²°ì‚°ì¼ ì´í›„ ì…ë ¥ëœ ì „í‘œ {len(back_dated)}ê±´ ë°œê²¬")
                        st.dataframe(back_dated)
        
        # B08: ì…ë ¥ì-ìŠ¹ì¸ì ë™ì¼ ê²€ì‚¬
        if scenario_b08:
            with st.expander("ğŸ‘¥ B08: ì…ë ¥ì-ìŠ¹ì¸ì ë™ì¼ ê²€ì‚¬ ê²°ê³¼", expanded=False):
                with st.spinner("ì…ë ¥ìì™€ ìŠ¹ì¸ìë¥¼ ë¶„ì„í•˜ëŠ” ì¤‘..."):
                    same_user_entries, error_msg = scenario_b08_create_approve_same(journal_df)
                    
                    if error_msg:
                        st.warning(f"âš ï¸ {error_msg}")
                    elif len(same_user_entries) == 0:
                        st.success("âœ… ì…ë ¥ìì™€ ìŠ¹ì¸ìê°€ ë™ì¼í•œ ì „í‘œê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    else:
                        st.warning(f"âš ï¸ ì…ë ¥ì-ìŠ¹ì¸ì ë™ì¼ ì „í‘œ {len(same_user_entries)}ê±´ ë°œê²¬")
                        st.dataframe(same_user_entries)
        
        # B09: ë¹„ì •ìƒ ê³„ì • ì¡°í•© ê²€ì‚¬
        if scenario_b09:
            with st.expander("ğŸ”— B09: ë¹„ì •ìƒ ê³„ì • ì¡°í•© ê²€ì‚¬ ê²°ê³¼", expanded=False):
                with st.spinner("ë¹„ì •ìƒ ê³„ì • ì¡°í•©ì„ ë¶„ì„í•˜ëŠ” ì¤‘..."):
                    unusual_combinations, error_msg = scenario_b09_corresponding_accounts(journal_df)
                    
                    if error_msg:
                        st.warning(f"âš ï¸ {error_msg}")
                    elif len(unusual_combinations) == 0:
                        st.success("âœ… ë¹„ì •ìƒì ì¸ ê³„ì • ì¡°í•©ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    else:
                        st.warning(f"âš ï¸ ë¹„ì •ìƒ ê³„ì • ì¡°í•© ì „í‘œ {len(unusual_combinations)}ê±´ ë°œê²¬")
                        st.dataframe(unusual_combinations)
    
    else:
        st.info("ğŸ“ ë¶„ê°œì¥ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")

with col2:
    st.header("ğŸ“Š ë°ì´í„° í˜„í™©")
    
    # ì—…ë¡œë“œëœ íŒŒì¼ í˜„í™©
    if prev_tb_file:
        st.success("âœ… ì „ê¸° ì‹œì‚°í‘œ")
        if prev_tb_df is not None:
            st.metric("ë ˆì½”ë“œ ìˆ˜", len(prev_tb_df))
    else:
        st.info("ğŸ“„ ì „ê¸° ì‹œì‚°í‘œ ëŒ€ê¸°ì¤‘")
    
    if journal_file:
        st.success("âœ… ë¶„ê°œì¥")
        if journal_df is not None:
            st.metric("ë¶„ê°œ ìˆ˜", len(journal_df))
            if 'ì „í‘œë²ˆí˜¸' in journal_df.columns:
                unique_vouchers = journal_df['ì „í‘œë²ˆí˜¸'].nunique()
                st.metric("ì „í‘œ ìˆ˜", unique_vouchers)
    else:
        st.info("ğŸ“„ ë¶„ê°œì¥ ëŒ€ê¸°ì¤‘")
    
    if curr_tb_file:
        st.success("âœ… ë‹¹ê¸° ì‹œì‚°í‘œ")
        if curr_tb_df is not None:
            st.metric("ë ˆì½”ë“œ ìˆ˜", len(curr_tb_df))
    else:
        st.info("ğŸ“„ ë‹¹ê¸° ì‹œì‚°í‘œ ëŒ€ê¸°ì¤‘")

# í‘¸í„°
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: gray;'>
    <p>íšŒê³„ê°ì‚¬ JET ìë™í™” í”„ë¡œê·¸ë¨ v1.0</p>
    <p>Â© 2025 Audit Analytics Solutions</p>
</div>
""", unsafe_allow_html=True)